{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a7ab63-2c6a-484f-8d52-96760f8cc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# transform is used to convert data into Tensor form with transformations\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    # To resize image\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    # To normalize image\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "root = './data',\n",
    "train = True,\n",
    "download = True,\n",
    "transform = trans\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "root = './data',\n",
    "train = False,\n",
    "download = True,\n",
    "transform = trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0a7887-52fa-41ca-bc8d-59beebf08008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# this is one of Hyper parameter, but let's select given below value\n",
    "batch_size = 512\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "# this will help us to create Grid of images\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(6, 16, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logit = self.classifier(x)\n",
    "        return logit\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    _, preds = torch.max(output, dim = 1)\n",
    "\n",
    "    return torch.sum(preds == labels).item() / len(preds)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "def eevaluate(model, loss_fn, val_dl, metric = None, device='cuda'):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        results = [loss_batch(model, loss_fn, x, y, metric = metric) for x, y in val_dl]\n",
    "\n",
    "        losses, nums, metrics = zip(*results)\n",
    "\n",
    "        total = np.sum(nums)\n",
    "\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "\n",
    "        avg_metric = None\n",
    "\n",
    "        if metric is not None:\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "\n",
    "    return avg_loss, total, avg_metric\n",
    "\n",
    "def loss_batch(model, loss_func, x, y, opt = None, metric = None):\n",
    "\n",
    "    pred = model(x)\n",
    "\n",
    "    loss = loss_func(pred, y)\n",
    "\n",
    "    if opt is not None:\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    metric_result = None\n",
    "\n",
    "    if metric is not None:\n",
    "\n",
    "        metric_result = metric(pred, y)\n",
    "\n",
    "    return loss.item(), len(x), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6edd56-3c5c-44e4-910b-6fa7e86faf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('lenet.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46f2f08-e533-4e4b-8fba-66b259aeeec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Losses: 0.03845255719994893, Accuracy: 98.9\n"
     ]
    }
   ],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_set, batch_size=256), device)\n",
    "result = eevaluate(model, F.cross_entropy, test_loader, metric = accuracy)\n",
    "result\n",
    "Accuracy = result[2] * 100\n",
    "Accuracy\n",
    "loss = result[0]\n",
    "print(\"Total Losses: {}, Accuracy: {}\".format(loss, Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3819e991-5fbd-4507-976c-620881ea9ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61470\n"
     ]
    }
   ],
   "source": [
    "layer_names2 = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "num_weights_per_layer2 = {name: model.state_dict()[name].numel() for name in layer_names2}\n",
    "n = 0\n",
    "for _ in layer_names2:\n",
    "  n = n + num_weights_per_layer2[_]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29c0ad10-b143-4d76-af33-058cffb0a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "0\n",
      "accuracy: 81.3\n",
      "1\n",
      "accuracy: 83.26\n",
      "2\n",
      "accuracy: 85.35000000000001\n",
      "3\n",
      "accuracy: 84.15\n",
      "4\n",
      "accuracy: 93.67\n",
      "5\n",
      "accuracy: 85.18\n",
      "6\n",
      "accuracy: 80.36\n",
      "7\n",
      "accuracy: 88.12\n",
      "8\n",
      "accuracy: 83.6\n",
      "9\n",
      "accuracy: 78.5\n",
      "10\n",
      "accuracy: 88.67\n",
      "11\n",
      "accuracy: 73.75\n",
      "12\n",
      "accuracy: 90.61\n",
      "13\n",
      "accuracy: 84.94\n",
      "14\n",
      "accuracy: 85.06\n",
      "15\n",
      "accuracy: 74.15\n",
      "16\n",
      "accuracy: 90.11\n",
      "17\n",
      "accuracy: 85.81\n",
      "18\n",
      "accuracy: 83.64\n",
      "19\n",
      "accuracy: 80.28\n",
      "20\n",
      "accuracy: 80.36\n",
      "21\n",
      "accuracy: 74.57000000000001\n",
      "22\n",
      "accuracy: 77.42\n",
      "23\n",
      "accuracy: 78.3\n",
      "24\n",
      "accuracy: 84.39\n",
      "25\n",
      "accuracy: 86.02\n",
      "26\n",
      "accuracy: 85.85000000000001\n",
      "27\n",
      "accuracy: 88.2\n",
      "28\n",
      "accuracy: 79.43\n",
      "29\n",
      "accuracy: 73.99\n",
      "30\n",
      "accuracy: 85.53\n",
      "31\n",
      "accuracy: 75.39\n",
      "32\n",
      "accuracy: 84.50999999999999\n",
      "33\n",
      "accuracy: 88.72\n",
      "34\n",
      "accuracy: 86.78\n",
      "35\n",
      "accuracy: 80.32000000000001\n",
      "36\n",
      "accuracy: 80.13\n",
      "37\n",
      "accuracy: 85.57000000000001\n",
      "38\n",
      "accuracy: 74.72999999999999\n",
      "39\n",
      "accuracy: 73.86\n",
      "40\n",
      "accuracy: 74.71\n",
      "41\n",
      "accuracy: 80.44\n",
      "42\n",
      "accuracy: 89.08\n",
      "43\n",
      "accuracy: 87.92\n",
      "44\n",
      "accuracy: 76.87\n",
      "45\n",
      "accuracy: 86.57000000000001\n",
      "46\n",
      "accuracy: 71.43\n",
      "47\n",
      "accuracy: 76.5\n",
      "48\n",
      "accuracy: 77.89\n",
      "49\n",
      "accuracy: 92.2\n",
      "50\n",
      "accuracy: 84.38\n",
      "51\n",
      "accuracy: 78.18\n",
      "52\n",
      "accuracy: 76.92\n",
      "53\n",
      "accuracy: 77.23\n",
      "54\n",
      "accuracy: 74.11\n",
      "55\n",
      "accuracy: 82.88\n",
      "56\n",
      "accuracy: 84.36\n",
      "57\n",
      "accuracy: 72.97\n",
      "58\n",
      "accuracy: 81.91000000000001\n",
      "59\n",
      "accuracy: 85.97\n",
      "60\n",
      "accuracy: 86.0\n",
      "61\n",
      "accuracy: 78.89\n",
      "62\n",
      "accuracy: 86.76\n",
      "63\n",
      "accuracy: 81.61\n",
      "64\n",
      "accuracy: 74.5\n",
      "65\n",
      "accuracy: 73.63\n",
      "66\n",
      "accuracy: 84.39999999999999\n",
      "67\n",
      "accuracy: 90.36999999999999\n",
      "68\n",
      "accuracy: 75.86\n",
      "69\n",
      "accuracy: 81.23\n",
      "70\n",
      "accuracy: 75.62\n",
      "71\n",
      "accuracy: 79.42\n",
      "72\n",
      "accuracy: 91.31\n",
      "73\n",
      "accuracy: 76.83\n",
      "74\n",
      "accuracy: 80.76\n",
      "75\n",
      "accuracy: 76.64999999999999\n",
      "76\n",
      "accuracy: 81.56\n",
      "77\n",
      "accuracy: 76.55999999999999\n",
      "78\n",
      "accuracy: 88.77000000000001\n",
      "79\n",
      "accuracy: 74.83999999999999\n",
      "80\n",
      "accuracy: 74.48\n",
      "81\n",
      "accuracy: 89.59\n",
      "82\n",
      "accuracy: 84.02\n",
      "83\n",
      "accuracy: 83.24000000000001\n",
      "84\n",
      "accuracy: 77.97\n",
      "85\n",
      "accuracy: 78.59\n",
      "86\n",
      "accuracy: 87.98\n",
      "87\n",
      "accuracy: 80.60000000000001\n",
      "88\n",
      "accuracy: 84.7\n",
      "89\n",
      "accuracy: 74.15\n",
      "90\n",
      "accuracy: 80.53\n",
      "91\n",
      "accuracy: 82.49\n",
      "92\n",
      "accuracy: 87.48\n",
      "93\n",
      "accuracy: 80.73\n",
      "94\n",
      "accuracy: 86.32\n",
      "95\n",
      "accuracy: 84.65\n",
      "96\n",
      "accuracy: 74.58\n",
      "97\n",
      "accuracy: 80.58999999999999\n",
      "98\n",
      "accuracy: 88.98\n",
      "99\n",
      "accuracy: 81.58\n",
      "average accuracy= 81.75919999999998\n",
      "accuracy drop= 17.140800000000027\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "repititions = 100\n",
    "BER = 0.01\n",
    "\n",
    "print(int(BER * n))\n",
    "acc = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(repititions):\n",
    "  model_copy = torch.load('lenet.pth')\n",
    "  model_copy = model_copy.to('cuda')\n",
    "  layer_names = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "  num_weights_per_layer = {name: model.state_dict()[name].numel() for name in layer_names}\n",
    "  state_dict = model_copy.state_dict()\n",
    "  for _ in range(int(BER * n)):\n",
    "    layer = random.choice(layer_names)\n",
    "    index = random.randint(0, num_weights_per_layer[layer] - 1)\n",
    "    weight = state_dict[layer].view(-1).to('cuda')\n",
    "        # print(weight)\n",
    "        # weight[weight_idx] += 0.01  # Perturb the weight slightly\n",
    "    \n",
    "    weight[index] = weight[index] + 0.1\n",
    "  model_copy.load_state_dict(state_dict)\n",
    "\n",
    "    # Evaluate the perturbed model on a validation set\n",
    "  model_copy.eval()\n",
    "  result = eevaluate(model_copy, F.cross_entropy, test_loader, metric = accuracy)\n",
    "  print(count)\n",
    "  print(\"accuracy:\", result[2] * 100)\n",
    "  acc.append(result[2] * 100)\n",
    "  count += 1\n",
    "\n",
    "avg_acc = sum(acc)/len(acc)\n",
    "print(\"average accuracy=\", avg_acc)\n",
    "print(\"accuracy drop=\", 98.9 - avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf0d419-219e-407d-be52-74fe66be13bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "0\n",
      "accuracy: 98.85000000000001\n",
      "1\n",
      "accuracy: 98.81\n",
      "2\n",
      "accuracy: 98.81\n",
      "3\n",
      "accuracy: 98.81\n",
      "4\n",
      "accuracy: 98.82\n",
      "5\n",
      "accuracy: 98.83999999999999\n",
      "6\n",
      "accuracy: 98.82\n",
      "7\n",
      "accuracy: 98.77\n",
      "8\n",
      "accuracy: 98.82\n",
      "9\n",
      "accuracy: 98.8\n",
      "10\n",
      "accuracy: 98.82\n",
      "11\n",
      "accuracy: 98.83\n",
      "12\n",
      "accuracy: 98.79\n",
      "13\n",
      "accuracy: 98.71\n",
      "14\n",
      "accuracy: 98.77\n",
      "15\n",
      "accuracy: 98.8\n",
      "16\n",
      "accuracy: 98.85000000000001\n",
      "17\n",
      "accuracy: 98.8\n",
      "18\n",
      "accuracy: 98.74000000000001\n",
      "19\n",
      "accuracy: 98.78\n",
      "20\n",
      "accuracy: 98.79\n",
      "21\n",
      "accuracy: 98.91\n",
      "22\n",
      "accuracy: 98.8\n",
      "23\n",
      "accuracy: 98.75\n",
      "24\n",
      "accuracy: 98.83\n",
      "25\n",
      "accuracy: 98.74000000000001\n",
      "26\n",
      "accuracy: 98.78\n",
      "27\n",
      "accuracy: 98.77\n",
      "28\n",
      "accuracy: 98.72\n",
      "29\n",
      "accuracy: 98.83\n",
      "30\n",
      "accuracy: 98.75\n",
      "31\n",
      "accuracy: 98.83\n",
      "32\n",
      "accuracy: 98.77\n",
      "33\n",
      "accuracy: 98.88\n",
      "34\n",
      "accuracy: 98.74000000000001\n",
      "35\n",
      "accuracy: 98.77\n",
      "36\n",
      "accuracy: 98.79\n",
      "37\n",
      "accuracy: 98.7\n",
      "38\n",
      "accuracy: 98.71\n",
      "39\n",
      "accuracy: 98.76\n",
      "40\n",
      "accuracy: 98.76\n",
      "41\n",
      "accuracy: 98.8\n",
      "42\n",
      "accuracy: 98.82\n",
      "43\n",
      "accuracy: 98.85000000000001\n",
      "44\n",
      "accuracy: 98.83\n",
      "45\n",
      "accuracy: 98.7\n",
      "46\n",
      "accuracy: 98.85000000000001\n",
      "47\n",
      "accuracy: 98.82\n",
      "48\n",
      "accuracy: 98.79\n",
      "49\n",
      "accuracy: 98.82\n",
      "50\n",
      "accuracy: 98.78\n",
      "51\n",
      "accuracy: 98.8\n",
      "52\n",
      "accuracy: 98.83999999999999\n",
      "53\n",
      "accuracy: 98.7\n",
      "54\n",
      "accuracy: 98.78\n",
      "55\n",
      "accuracy: 98.74000000000001\n",
      "56\n",
      "accuracy: 98.72999999999999\n",
      "57\n",
      "accuracy: 98.77\n",
      "58\n",
      "accuracy: 98.87\n",
      "59\n",
      "accuracy: 98.83999999999999\n",
      "60\n",
      "accuracy: 98.71\n",
      "61\n",
      "accuracy: 98.76\n",
      "62\n",
      "accuracy: 98.8\n",
      "63\n",
      "accuracy: 98.72\n",
      "64\n",
      "accuracy: 98.72999999999999\n",
      "65\n",
      "accuracy: 98.85000000000001\n",
      "66\n",
      "accuracy: 98.71\n",
      "67\n",
      "accuracy: 98.78\n",
      "68\n",
      "accuracy: 98.81\n",
      "69\n",
      "accuracy: 98.76\n",
      "70\n",
      "accuracy: 98.81\n",
      "71\n",
      "accuracy: 98.71\n",
      "72\n",
      "accuracy: 98.8\n",
      "73\n",
      "accuracy: 98.75\n",
      "74\n",
      "accuracy: 98.69\n",
      "75\n",
      "accuracy: 98.78\n",
      "76\n",
      "accuracy: 98.72\n",
      "77\n",
      "accuracy: 98.77\n",
      "78\n",
      "accuracy: 98.81\n",
      "79\n",
      "accuracy: 98.75\n",
      "80\n",
      "accuracy: 98.7\n",
      "81\n",
      "accuracy: 98.79\n",
      "82\n",
      "accuracy: 98.76\n",
      "83\n",
      "accuracy: 98.72999999999999\n",
      "84\n",
      "accuracy: 98.8\n",
      "85\n",
      "accuracy: 98.74000000000001\n",
      "86\n",
      "accuracy: 98.79\n",
      "87\n",
      "accuracy: 98.72999999999999\n",
      "88\n",
      "accuracy: 98.8\n",
      "89\n",
      "accuracy: 98.77\n",
      "90\n",
      "accuracy: 98.76\n",
      "91\n",
      "accuracy: 98.82\n",
      "92\n",
      "accuracy: 98.76\n",
      "93\n",
      "accuracy: 98.79\n",
      "94\n",
      "accuracy: 98.77\n",
      "95\n",
      "accuracy: 98.78\n",
      "96\n",
      "accuracy: 98.78\n",
      "97\n",
      "accuracy: 98.72999999999999\n",
      "98\n",
      "accuracy: 98.76\n",
      "99\n",
      "accuracy: 98.83999999999999\n",
      "average accuracy= 98.78170000000001\n",
      "accuracy drop= 0.11829999999999075\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "repititions = 100\n",
    "BER = 0.01\n",
    "\n",
    "print(int(BER * n))\n",
    "acc = []\n",
    "\n",
    "count = 0\n",
    "protected_layer = 'features.0.weight'\n",
    "\n",
    "for i in range(repititions):\n",
    "  model_copy = torch.load('lenet.pth')\n",
    "  model_copy = model_copy.to('cuda')\n",
    "  layer_names = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "  num_weights_per_layer = {name: model.state_dict()[name].numel() for name in layer_names}\n",
    "  state_dict = model_copy.state_dict()\n",
    "  for _ in range(int(BER * n)):\n",
    "    layer = random.choice(layer_names)\n",
    "    index = random.randint(0, num_weights_per_layer[layer] - 1)\n",
    "    weight = state_dict[layer].view(-1).to('cuda')\n",
    "        # print(weight)\n",
    "        # weight[weight_idx] += 0.01  # Perturb the weight slightly\n",
    "    if layer == protected_layer:\n",
    "        # print(\"protected\")\n",
    "        weight[index] = weight[index]\n",
    "    else:\n",
    "        weight[index] = weight[index] + 0.1\n",
    "  model_copy.load_state_dict(state_dict)\n",
    "\n",
    "    # Evaluate the perturbed model on a validation set\n",
    "  model_copy.eval()\n",
    "  result = eevaluate(model_copy, F.cross_entropy, test_loader, metric = accuracy)\n",
    "  print(count)\n",
    "  print(\"accuracy:\", result[2] * 100)\n",
    "  acc.append(result[2] * 100)\n",
    "  count += 1\n",
    "\n",
    "avg_acc = sum(acc)/len(acc)\n",
    "print(\"average accuracy=\", avg_acc)\n",
    "print(\"accuracy drop=\", 98.9 - avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d984002-b20a-4d1b-b379-c52af60d4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights in layer 'features.0.weight': 150\n"
     ]
    }
   ],
   "source": [
    "layer_name = 'features.0.weight'\n",
    "\n",
    "# Get the number of weights in the specified layer\n",
    "if layer_name in state_dict:\n",
    "    num_weights = state_dict[layer_name].numel()  # Get the number of elements in the weight tensor\n",
    "    print(f\"Number of weights in layer '{layer_name}': {num_weights}\")\n",
    "else:\n",
    "    print(f\"Layer '{layer_name}' not found in the model's state_dict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830290e-1a6b-44ed-a970-e1117e5cd299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
