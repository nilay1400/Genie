{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2214798-2508-42e3-a650-aede85b36990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# print(torch.__version__)\n",
    "# print(DEVICE)\n",
    "\n",
    "\n",
    "train_csv = pd.read_csv('./kaggle/input/fashionmnist/fashion-mnist_train.csv')\n",
    "test_csv = pd.read_csv('./kaggle/input/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "inputSize = 8000\n",
    "train_csv=train_csv[:inputSize]\n",
    "# len(train_csv)\n",
    "\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):        \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label, image = [], []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28).astype('float32')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.images[idx]      \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            # transfrom the numpy array to PIL image before the transform function\n",
    "            pil_image = Image.fromarray(np.uint8(image)) \n",
    "            image = self.transform(pil_image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "\n",
    "AlexTransform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    FashionDataset(train_csv, transform=AlexTransform), \n",
    "    batch_size=100, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    FashionDataset(train_csv, transform=AlexTransform), \n",
    "    batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "class fasion_mnist_alexnet(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = self.fc3(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def testt(model, device, test_loader):\n",
    "    # model.eval()\n",
    "    # test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # test_loss += criterion(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        # test_loss /= len(test_loader.dataset)  # loss之和除以data数量 -> mean\n",
    "        # accuracy_val.append(100. * correct / len(test_loader.dataset))\n",
    "        # print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            # test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        # print(test_loss)\n",
    "        # print(correct)\n",
    "        # print(accuracy_val)\n",
    "        acc = 100. * correct / len(test_loader.dataset)\n",
    "        return(acc)\n",
    "    \n",
    "\n",
    "model = torch.load('alex.pth')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9ab74a-eb60-44db-8f48-8432a33b4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 6.8213342009694315\n",
      "Accuracy: 95.4375 %\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "model = model.to('cuda')\n",
    "    # model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "dataloader =test_loader\n",
    "model.eval()\n",
    "acc = testt(model, DEVICE, dataloader)\n",
    "    # print(acc)ts.writerow(csv_output)\n",
    "print('Total Time:', timeit.default_timer() - start_time)\n",
    "print('Accuracy: %.4f %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91edfebd-3650-4cb2-a530-8d53b2601ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting deap\n",
      "  Downloading deap-1.4.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m856.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from deap) (1.19.5)\n",
      "Installing collected packages: deap\n",
      "Successfully installed deap-1.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55e1bf2-6edb-4481-893a-b289ad70f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c9ffe0-69a0-4c12-89ea-e5228bcc8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')\n",
    "# Define the evaluation function\n",
    "def evaluate(individual):\n",
    "    # print(\"Evaluating individual:\", individual)\n",
    "    model_copy = torch.load('alex.pth')\n",
    "    model_copy = model_copy.to('cuda')\n",
    "\n",
    "###################################################################\n",
    "\n",
    "    state_dict = model_copy.state_dict()\n",
    "    for layer_name, weight_idx in individual:\n",
    "        weight = state_dict[layer_name].view(-1).to('cuda')\n",
    "        # print(weight)\n",
    "        # weight[weight_idx] += 0.01  # Perturb the weight slightly\n",
    "        \n",
    "        weight[weight_idx] = weight[weight_idx] + 0.1\n",
    "\n",
    "\n",
    "    # Load the perturbed weights back into the model\n",
    "    model_copy.load_state_dict(state_dict)\n",
    "\n",
    "    # Evaluate the perturbed model on a validation set\n",
    "    model_copy.eval()\n",
    "    result = testt(model_copy, DEVICE, dataloader)\n",
    "    Accuracy = result\n",
    "    loss = 95.4375 - Accuracy\n",
    "\n",
    "\n",
    "    # Return the loss as fitness (higher loss indicates more critical weight)\n",
    "    return loss,\n",
    "\n",
    "# Create the fitness and individual classes\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximize the function\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "def custom_mutate(individual, indpb):\n",
    "    # print(\"Before mutation:\", individual)\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            layer, index = individual[i]\n",
    "            new_index = random.randint(0, num_weights_per_layer[layer] - 1)\n",
    "            individual[i] = (layer, new_index)\n",
    "    # print(\"After mutation:\", individual)\n",
    "    return individual,\n",
    "\n",
    "def custom_crossover(ind1, ind2):\n",
    "    # print(\"Before crossover:\", ind1, ind2)\n",
    "    tools.cxTwoPoint(ind1, ind2)\n",
    "    # print(\"After crossover:\", ind1, ind2)\n",
    "    return ind1, ind2\n",
    "\n",
    "\n",
    "# Attribute generator: (layer, index) pair\n",
    "layer_names = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "num_weights_per_layer = {name: model.state_dict()[name].numel() for name in layer_names}\n",
    "def random_weight():\n",
    "    layer = random.choice(layer_names)\n",
    "    index = random.randint(0, num_weights_per_layer[layer] - 1)\n",
    "    # print(layer,index)\n",
    "    return (layer, index)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, random_weight, n=10)  # Each individual perturbs 5 weights\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Register the genetic operators\n",
    "toolbox.register(\"mutate\", custom_mutate, indpb=0.2)\n",
    "toolbox.register(\"mate\", custom_crossover)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02860d0-eccc-4f5f-941d-1a072527b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin    \tmax   \n",
      "0  \t100   \t-0.10025\t-0.3875\t0.2875\n",
      "Generation 1\n",
      "1  \t62    \t-0.04575\t-0.4125\t0.3125\n",
      "Generation 2\n",
      "2  \t55    \t0.0055  \t-0.525 \t0.3125\n",
      "Generation 3\n",
      "3  \t68    \t0.00325 \t-0.3875\t0.3125\n",
      "Generation 4\n",
      "4  \t58    \t0.01725 \t-0.4875\t0.3125\n",
      "Generation 5\n",
      "5  \t56    \t0.032875\t-0.35  \t0.3125\n",
      "Generation 6\n",
      "6  \t57    \t0.051625\t-0.4375\t0.375 \n",
      "Generation 7\n",
      "7  \t59    \t0.06725 \t-0.4875\t0.375 \n",
      "Generation 8\n",
      "8  \t61    \t0.071125\t-0.475 \t0.3625\n",
      "Generation 9\n",
      "9  \t65    \t0.07675 \t-0.6   \t0.5375\n",
      "Generation 10\n",
      "10 \t62    \t0.091625\t-0.375 \t0.525 \n",
      "Generation 11\n",
      "11 \t67    \t0.125375\t-0.3875\t0.525 \n",
      "Generation 12\n",
      "12 \t67    \t0.127125\t-0.4375\t0.5125\n",
      "Generation 13\n",
      "13 \t59    \t0.165375\t-0.2375\t0.5125\n",
      "Generation 14\n",
      "14 \t59    \t0.253625\t-0.2   \t0.575 \n",
      "Generation 15\n",
      "15 \t55    \t0.22675 \t-0.4875\t0.575 \n",
      "Generation 16\n",
      "16 \t62    \t0.229625\t-0.2625\t0.575 \n",
      "Generation 17\n",
      "17 \t48    \t0.265875\t-0.3   \t0.575 \n",
      "Generation 18\n",
      "18 \t60    \t0.252   \t-0.6375\t0.6   \n",
      "Generation 19\n",
      "19 \t53    \t0.242625\t-0.2   \t0.6   \n",
      "Generation 20\n",
      "20 \t63    \t0.227625\t-0.2875\t0.6   \n",
      "Generation 21\n",
      "21 \t51    \t0.25575 \t-0.2125\t0.6   \n",
      "Generation 22\n",
      "22 \t59    \t0.248   \t-0.325 \t0.6   \n",
      "Generation 23\n",
      "23 \t61    \t0.226875\t-0.1625\t0.6   \n",
      "Generation 24\n",
      "24 \t72    \t0.1975  \t-0.2875\t0.6   \n",
      "Generation 25\n",
      "25 \t55    \t0.2375  \t-0.1375\t0.6   \n",
      "Generation 26\n",
      "26 \t60    \t0.24175 \t-0.1625\t0.6   \n",
      "Generation 27\n",
      "27 \t64    \t0.2095  \t-0.3   \t0.5625\n",
      "Generation 28\n",
      "28 \t57    \t0.22175 \t-0.5   \t0.5625\n",
      "Generation 29\n",
      "29 \t60    \t0.230375\t-0.1625\t0.55  \n",
      "Generation 30\n",
      "31 \t57    \t0.22175 \t-0.275 \t0.525 \n",
      "Generation 32\n",
      "32 \t68    \t0.205875\t-0.1625\t0.525 \n",
      "Generation 33\n",
      "33 \t57    \t0.22375 \t-0.2125\t0.5375\n",
      "Generation 34\n",
      "34 \t59    \t0.24425 \t-0.225 \t0.575 \n",
      "Generation 35\n",
      "35 \t62    \t0.217625\t-0.25  \t0.575 \n",
      "Generation 36\n",
      "36 \t50    \t0.25375 \t-0.1625\t0.575 \n",
      "Generation 37\n",
      "37 \t66    \t0.22725 \t-0.325 \t0.575 \n",
      "Generation 38\n",
      "38 \t48    \t0.2525  \t-0.225 \t0.575 \n",
      "Generation 39\n",
      "39 \t63    \t0.2405  \t-0.2875\t0.575 \n",
      "Generation 40\n",
      "40 \t58    \t0.282875\t-0.1875\t0.575 \n",
      "Best individual is:  [('fc1.weight', 18885626), ('conv1.0.weight', 1330), ('conv5.0.weight', 165409), ('fc3.weight', 17345), ('conv4.0.weight', 749789), ('conv3.0.weight', 402219), ('conv5.0.weight', 670532), ('conv1.0.weight', 1229), ('fc2.weight', 16510703), ('conv4.0.weight', 585118)]\n",
      "Fitness:  0.5999999999999943\n"
     ]
    }
   ],
   "source": [
    "from deap import tools, base, creator, algorithms\n",
    "\n",
    "def eaSimpleWithDebugging(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
    "                          halloffame=None, verbose=__debug__):\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "        print(f\"Generation {gen}\")\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        # Apply crossover and mutation on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < cxpb:\n",
    "                # print(f\"Before mate: {child1}, {child2}\")\n",
    "                toolbox.mate(child1, child2)\n",
    "                # print(f\"After mate: {child1}, {child2}\")\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < mutpb:\n",
    "                # print(f\"Before mutate: {mutant}\")\n",
    "                toolbox.mutate(mutant)\n",
    "                # print(f\"After mutate: {mutant}\")\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(42)\n",
    "\n",
    "    # Create an initial population of 100 individuals\n",
    "    population = toolbox.population(n=100)\n",
    "\n",
    "    # Define statistics to keep track of the progress\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values[0])  # Extract the first element of the fitness tuple\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", min)\n",
    "    stats.register(\"max\", max)\n",
    "\n",
    "    # Hall of Fame to keep the best individual\n",
    "    hof = tools.HallOfFame(1)\n",
    "\n",
    "    # Run the genetic algorithm\n",
    "    population, logbook = eaSimpleWithDebugging(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=40,\n",
    "                                                stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    # Print the best individual\n",
    "    print(\"Best individual is: \", hof[0])\n",
    "    print(\"Fitness: \", hof[0].fitness.values[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1399f4af-523f-4eba-b426-b756bfb0486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58289504\n"
     ]
    }
   ],
   "source": [
    "layer_names2 = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "num_weights_per_layer2 = {name: model.state_dict()[name].numel() for name in layer_names2}\n",
    "n = 0\n",
    "for _ in layer_names2:\n",
    "  n = n + num_weights_per_layer2[_]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a67947-eb3c-4742-aa70-0bf90a237e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "repititions = 1\n",
    "BER = 0.0001\n",
    "\n",
    "print(int(BER * n))\n",
    "acc = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(repititions):\n",
    "  model_copy = torch.load('alex.pth')\n",
    "  model_copy = model_copy.to('cuda')\n",
    "  layer_names = [name for name in model.state_dict().keys() if 'weight' in name]\n",
    "  num_weights_per_layer = {name: model.state_dict()[name].numel() for name in layer_names}\n",
    "  state_dict = model_copy.state_dict()\n",
    "  for _ in range(int(BER * n)):\n",
    "    layer = random.choice(layer_names)\n",
    "    index = random.randint(0, num_weights_per_layer[layer] - 1)\n",
    "    weight = state_dict[layer].view(-1).to('cuda')\n",
    "        # print(weight)\n",
    "        # weight[weight_idx] += 0.01  # Perturb the weight slightly\n",
    "    \n",
    "    weight[index] = weight[index] + 0.1\n",
    "  model_copy.load_state_dict(state_dict)\n",
    "\n",
    "    # Evaluate the perturbed model on a validation set\n",
    "  # model_copy.eval()\n",
    "  # result = eevaluate(model_copy, F.cross_entropy, test_loader, metric = accuracy)\n",
    "  # print(count)\n",
    "  # print(\"accuracy:\", result[2] * 100)\n",
    "  # acc.append(result[2] * 100)\n",
    "\n",
    "  model_copy.eval()\n",
    "  result = testt(model_copy, DEVICE, dataloader)\n",
    "  print(\"accuracy:\", result)\n",
    "  acc.append(result)\n",
    "  count += 1\n",
    "\n",
    "avg_acc = sum(acc)/len(acc)\n",
    "print(\"average accuracy=\", avg_acc)\n",
    "print(\"accuracy drop=\", 95.4375 - avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0da26d-b31a-44a1-9425-9708471a0868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
